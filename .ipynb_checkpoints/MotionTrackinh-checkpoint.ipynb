{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jerkOffData=pd.read_csv(\"sketch_200905a/JerkOff.csv\")\n",
    "WalkData=pd.read_csv(\"sketch_200905a/WalkAround.csv\")\n",
    "XucCatData=pd.read_csv(\"sketch_200905a/XucCat.csv\")\n",
    "HipHopData=pd.read_csv(\"sketch_200905a/HipHop.csv\")\n",
    "SitData=pd.read_csv(\"sketch_200905a/SitAndUsingComputer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>LandmarkID</th>\n",
       "      <th>AcX</th>\n",
       "      <th>AcY</th>\n",
       "      <th>AcZ</th>\n",
       "      <th>GyX</th>\n",
       "      <th>GyY</th>\n",
       "      <th>GyZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-9-6-1-22-58-4168</td>\n",
       "      <td>1</td>\n",
       "      <td>6568</td>\n",
       "      <td>-13808</td>\n",
       "      <td>-10224</td>\n",
       "      <td>-3408</td>\n",
       "      <td>-686</td>\n",
       "      <td>-452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-9-6-1-22-58-4172</td>\n",
       "      <td>2</td>\n",
       "      <td>2776</td>\n",
       "      <td>-15804</td>\n",
       "      <td>-792</td>\n",
       "      <td>-3456</td>\n",
       "      <td>976</td>\n",
       "      <td>-8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-9-6-1-22-58-4243</td>\n",
       "      <td>4</td>\n",
       "      <td>304</td>\n",
       "      <td>-16524</td>\n",
       "      <td>-5800</td>\n",
       "      <td>-3712</td>\n",
       "      <td>-1456</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-9-6-1-22-58-4331</td>\n",
       "      <td>3</td>\n",
       "      <td>-3256</td>\n",
       "      <td>-15872</td>\n",
       "      <td>1172</td>\n",
       "      <td>-4064</td>\n",
       "      <td>324</td>\n",
       "      <td>-453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-9-6-1-22-58-4644</td>\n",
       "      <td>1</td>\n",
       "      <td>-3144</td>\n",
       "      <td>-17960</td>\n",
       "      <td>-12304</td>\n",
       "      <td>-3408</td>\n",
       "      <td>14325</td>\n",
       "      <td>-19773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>1083</td>\n",
       "      <td>2020-9-6-1-25-13-139869</td>\n",
       "      <td>3</td>\n",
       "      <td>-4816</td>\n",
       "      <td>-12632</td>\n",
       "      <td>7784</td>\n",
       "      <td>-3920</td>\n",
       "      <td>-241</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1084</td>\n",
       "      <td>2020-9-6-1-25-14-140188</td>\n",
       "      <td>1</td>\n",
       "      <td>16588</td>\n",
       "      <td>3792</td>\n",
       "      <td>-4620</td>\n",
       "      <td>-3280</td>\n",
       "      <td>-601</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>1085</td>\n",
       "      <td>2020-9-6-1-25-14-140202</td>\n",
       "      <td>2</td>\n",
       "      <td>-7528</td>\n",
       "      <td>-13376</td>\n",
       "      <td>-5940</td>\n",
       "      <td>-3488</td>\n",
       "      <td>-406</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>1086</td>\n",
       "      <td>2020-9-6-1-25-14-140275</td>\n",
       "      <td>4</td>\n",
       "      <td>6912</td>\n",
       "      <td>1116</td>\n",
       "      <td>15384</td>\n",
       "      <td>-3840</td>\n",
       "      <td>-292</td>\n",
       "      <td>-72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>1087</td>\n",
       "      <td>2020-9-6-1-25-14-140362</td>\n",
       "      <td>3</td>\n",
       "      <td>-4864</td>\n",
       "      <td>-12560</td>\n",
       "      <td>8068</td>\n",
       "      <td>-3936</td>\n",
       "      <td>-280</td>\n",
       "      <td>-57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1088 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                TimeStamp  LandmarkID    AcX    AcY    AcZ   GyX  \\\n",
       "0        0    2020-9-6-1-22-58-4168           1   6568 -13808 -10224 -3408   \n",
       "1        1    2020-9-6-1-22-58-4172           2   2776 -15804   -792 -3456   \n",
       "2        2    2020-9-6-1-22-58-4243           4    304 -16524  -5800 -3712   \n",
       "3        3    2020-9-6-1-22-58-4331           3  -3256 -15872   1172 -4064   \n",
       "4        4    2020-9-6-1-22-58-4644           1  -3144 -17960 -12304 -3408   \n",
       "...    ...                      ...         ...    ...    ...    ...   ...   \n",
       "1083  1083  2020-9-6-1-25-13-139869           3  -4816 -12632   7784 -3920   \n",
       "1084  1084  2020-9-6-1-25-14-140188           1  16588   3792  -4620 -3280   \n",
       "1085  1085  2020-9-6-1-25-14-140202           2  -7528 -13376  -5940 -3488   \n",
       "1086  1086  2020-9-6-1-25-14-140275           4   6912   1116  15384 -3840   \n",
       "1087  1087  2020-9-6-1-25-14-140362           3  -4864 -12560   8068 -3936   \n",
       "\n",
       "        GyY    GyZ  \n",
       "0      -686   -452  \n",
       "1       976  -8251  \n",
       "2     -1456   2218  \n",
       "3       324   -453  \n",
       "4     14325 -19773  \n",
       "...     ...    ...  \n",
       "1083   -241      7  \n",
       "1084   -601    147  \n",
       "1085   -406      6  \n",
       "1086   -292    -72  \n",
       "1087   -280    -57  \n",
       "\n",
       "[1088 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jerkOffData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-9-6-1-22-58-4644'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jerkOffData['TimeStamp'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_object_1 = datetime.strptime(jerkOffData['TimeStamp'][0], '%Y-%m-%d-%H-%M-%S-%f')\n",
    "datetime_object_2 = datetime.strptime(jerkOffData['TimeStamp'][8], '%Y-%m-%d-%H-%M-%S-%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-06 01:22:58.416800\n",
      "2020-09-06 01:22:59.514600\n"
     ]
    }
   ],
   "source": [
    "print(datetime_object_1)\n",
    "print(datetime_object_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist=datetime_object_2-datetime_object_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjerkOff = jerkOffData[['LandmarkID','AcX','AcY','AcZ','GyX','GyY','GyZ']]\n",
    "dfWalk = WalkData[['LandmarkID','AcX','AcY','AcZ','GyX','GyY','GyZ']]\n",
    "dfXucCat = XucCatData[['LandmarkID','AcX','AcY','AcZ','GyX','GyY','GyZ']]\n",
    "dfHipHop = HipHopData[['LandmarkID','AcX','AcY','AcZ','GyX','GyY','GyZ']]\n",
    "dfSit = SitData[['LandmarkID','AcX','AcY','AcZ','GyX','GyY','GyZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocking(big_x):\n",
    "    newCons=4\n",
    "    newRow=[]\n",
    "    newDF = np.zeros(shape=(0,96))\n",
    "    for row in big_x:\n",
    "        newRow=newRow+list(row)\n",
    "        newCons-=1\n",
    "        if newCons==0:\n",
    "            newRow=np.array(newRow)\n",
    "            newRow=newRow.reshape((1,newRow.shape[0]))\n",
    "            newDF = np.concatenate((newDF,newRow))\n",
    "            newCons=4\n",
    "            newRow=[]\n",
    "    return newDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_normalize(df1,types=\"default\",label=-1):\n",
    "    newdf = pd.DataFrame( columns =['AcX_1','AcY_1','AcZ_1','GyX_1','GyY_1','GyZ_1','AcX_2','AcY_2','AcZ_2','GyX_2','GyY_2','GyZ_2','AcX_3','AcY_3','AcZ_3','GyX_3','GyY_3','GyZ_3','AcX_4','AcY_4','AcZ_4','GyX_4','GyY_4','GyZ_4']) \n",
    "\n",
    "    acceptPack=[1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4]\n",
    "    madik={}\n",
    "    for index, row in df1.iterrows():\n",
    "        for keys in (dict(row)):\n",
    "            if(keys!='LandmarkID'):\n",
    "                if(row['LandmarkID'] in acceptPack):\n",
    "                    acceptPack.remove(row['LandmarkID'])\n",
    "                    #print(str(keys)+\"_\"+str(row['LandmarkID']))\n",
    "                    madik[str(keys)+\"_\"+str(row['LandmarkID'])]=row[str(keys)]  \n",
    "        if(len(acceptPack)<1):\n",
    "            newdf=newdf.append(madik,ignore_index=True)\n",
    "            madik={}\n",
    "            acceptPack=[1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4]\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(newdf.values)\n",
    "    \n",
    "    if types==\"numpy\" and label!=-1:\n",
    "        x_fn=pd.DataFrame(x_scaled).values\n",
    "        x_fn=blocking(x_fn)\n",
    "        y_fn=np.zeros((x_fn.shape[0], 1))\n",
    "        y_fn.fill(label)\n",
    "        return x_fn,y_fn\n",
    "    else:   \n",
    "        return pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1,y_1 = flatten_normalize(dfjerkOff,\"numpy\",1)\n",
    "x_2,y_2 = flatten_normalize(dfWalk,\"numpy\",2)\n",
    "x_3,y_3 = flatten_normalize(dfXucCat,\"numpy\",3)\n",
    "x_4,y_4 = flatten_normalize(dfHipHop,\"numpy\",4)\n",
    "x_5,y_5 = flatten_normalize(dfSit,\"numpy\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((x_1, x_2,x_3,x_4,x_5))\n",
    "Y=np.concatenate((y_1, y_2,y_3,y_4,y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
    "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
    "input_dim = 96\n",
    "\n",
    "units = 64\n",
    "output_size = 6  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 96)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 100.).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "accuracy = svm_model_linear.score(X_test, y_test) \n",
    "svm_model_linear.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9908256880733946"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9724770642201835"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = build_model(allow_cudnn_kernel=True)\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "model.score(X_test, y_test) \n",
    "# model.compile(\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     optimizer=\"sgd\",\n",
    "#     metrics=[\"accuracy\"],\n",
    "# )\n",
    "\n",
    "\n",
    "# model.fit(\n",
    "#     X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([x_3[0],x_3[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 96)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3., 3.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "clf = LDA(solver='eigen')\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)\n",
    "clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38257136, 0.13526192, 0.41735782, 0.16666667, 0.54689993,\n",
       "       0.39858957, 0.84155791, 0.24074074, 0.68785496, 0.57142857,\n",
       "       0.34306951, 0.40051709, 0.6189781 , 0.40329973, 0.56894499,\n",
       "       0.2       , 0.80855397, 0.26170213, 0.27009519, 0.02007328,\n",
       "       0.32099157, 0.64705882, 0.50031151, 0.53385214, 0.10083546,\n",
       "       0.        , 0.37885071, 0.16666667, 0.8390223 , 0.00478976,\n",
       "       0.65803426, 0.5256734 , 0.64809961, 0.42857143, 0.        ,\n",
       "       0.        , 0.78613139, 0.16086159, 0.62610145, 0.13333333,\n",
       "       0.96053283, 0.2192766 , 0.11885246, 0.16695874, 0.35056955,\n",
       "       0.70588235, 0.42721001, 0.30788128, 0.1484103 , 0.08157415,\n",
       "       0.67224526, 0.25      , 0.62842019, 0.36463323, 0.65395595,\n",
       "       0.15614478, 0.72892093, 0.57142857, 0.31570912, 0.67880695,\n",
       "       0.8919708 , 0.28643446, 0.41414623, 0.06666667, 0.73231684,\n",
       "       0.33068085, 0.16657853, 0.11247411, 0.27838518, 0.70588235,\n",
       "       0.46835268, 0.41689174, 0.        , 0.07531926, 0.64292062,\n",
       "       0.25      , 0.39907757, 0.44265536, 0.72022838, 0.15740741,\n",
       "       0.70762342, 0.42857143, 0.20257131, 0.65767386, 0.84233577,\n",
       "       0.3588451 , 0.58609193, 0.06666667, 0.97126658, 0.30655319,\n",
       "       0.16988366, 0.        , 0.30465325, 0.70588235, 0.8003092 ,\n",
       "       0.63694209])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
